{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import requests\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def words2vector(self, sentence: str):\n",
    "        sentence = \"This is an example sentence.\"\n",
    "        tokens = self.tokenizer.tokenize(sentence)\n",
    "\n",
    "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_ids = [self.tokenizer.cls_token_id] + input_ids + [self.tokenizer.sep_token_id]\n",
    "\n",
    "        max_length = 64\n",
    "        input_ids = input_ids + [self.tokenizer.pad_token_id] * (max_length - len(input_ids))\n",
    "        input_tensor = torch.tensor([input_ids])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_tensor)\n",
    "            embedding = outputs[0][:, 0, :].numpy()\n",
    "\n",
    "        return embedding[0]\n",
    "    \n",
    "model = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[-0.64,0.22,0.31,0.69,-0.21,-0.58,0.60,-0.13,0.31,-0.11,-0.37,-0.45,-0.33,\\n 0.67,0.60,0.67,-0.18,0.52,0.08,-0.30,0.42,0.47,0.93,0.11,-0.05,-0.07,\\n -0.05,-1.07,-0.51,-0.03,-0.48,0.53,0.07,-0.07,0.41,-0.47,-0.67,-0.21,0.41,\\n 0.21,0.03,-0.65,0.83,0.07,-0.25,-0.58,-3.69,0.28,0.01,-0.50,-0.21,-0.29,\\n 0.54,0.20,0.18,0.82,0.03,-0.56,1.60,0.22,0.11,0.54,-0.72,0.02,-0.07,0.66,\\n 0.21,-0.10,-0.67,0.28,0.08,0.46,0.54,0.12,-0.08,-0.36,-0.38,1.25,-0.58,\\n -0.26,0.24,-0.32,0.02,-0.85,0.55,0.26,0.58,-0.52,-0.63,0.20,0.19,0.08,\\n 0.43,0.35,0.11,-0.21,0.13,0.13,-0.24,-0.01,-0.61,1.07,0.40,-0.35,-0.11,\\n 0.05,-1.37,0.06,-0.13,0.23,0.19,0.51,-0.71,0.04,0.51,0.25,0.37,-0.38,0.68,\\n -0.43,0.49,-0.03,0.18,0.07,-0.04,0.04,0.05,-1.54,0.37,0.90,0.03,0.34,\\n -0.40,0.11,-0.48,-0.64,-0.00,0.16,-0.10,0.08,-1.20,-0.61,-0.48,-0.75,0.26,\\n -0.02,0.22,0.58,-0.54,-0.33,-0.14,0.02,-1.13,-0.83,-0.33,-0.78,0.90,-0.05,\\n -0.20,0.89,0.26,0.65,0.16,0.51,-0.19,0.04,0.71,0.43,-0.10,-0.24,0.01,0.01,\\n 0.71,-0.74,-0.01,0.51,0.53,0.27,0.81,-0.11,-0.73,0.08,-0.49,-0.09,0.12,\\n 0.40,0.34,0.87,-0.06,0.81,-1.59,-0.34,0.66,0.42,0.42,0.18,-0.53,0.61,\\n -0.08,-0.21,-0.14,0.58,-0.18,0.47,0.10,2.11,0.06,-0.10,-0.16,-0.15,-0.60,\\n -0.55,-0.65,0.43,-0.30,-0.63,-0.48,-0.30,0.10,0.31,-0.39,-0.66,-0.48,0.52,\\n -0.02,-0.45,-0.71,-0.47,0.10,-1.57,0.08,-0.96,-0.39,-0.27,-0.38,0.26,0.14,\\n -0.38,0.27,0.39,-0.36,0.85,0.19,-0.23,-0.25,0.00,-0.15,-0.58,0.00,-0.05,\\n -0.03,0.10,-0.09,0.39,0.14,0.07,-0.23,0.18,-0.82,-0.70,-0.16,0.01,-0.54,\\n 0.39,-0.14,0.02,-0.05,-0.08,-0.05,-0.23,-0.04,-0.81,-0.41,0.61,0.20,-0.40,\\n 0.94,-0.37,-0.01,-0.11,0.21,0.16,-0.70,0.08,-0.46,-0.56,0.39,-0.44,0.76,\\n 0.26,-0.50,0.69,-0.17,0.32,0.15,-0.76,0.13,-0.40,0.33,0.68,-0.43,0.69,\\n -0.87,0.94,0.39,-0.13,-0.18,0.54,-4.43,0.44,-0.47,-0.01,-0.06,0.49,0.94,\\n 0.49,-0.43,0.13,0.03,0.60,-0.10,0.04,-0.60,-0.42,1.07,0.06,0.10,0.50,\\n -0.73,0.13,0.50,-0.40,0.50,0.33,-0.20,0.05,-0.12,0.53,-0.18,-0.92,0.32,\\n -0.58,-0.11,-0.05,-0.11,-0.58,0.73,-0.44,0.57,-0.84,-0.04,-0.04,0.71,\\n -0.32,0.03,1.14,0.36,0.67,0.10,0.26,0.24,0.00,-0.15,-0.42,0.16,-0.26,\\n -0.53,0.27,0.88,0.33,-0.69,0.23,0.35,-1.10,0.06,-0.19,-1.33,0.52,-0.96,\\n -0.11,0.07,-1.15,0.53,-0.49,0.05,0.03,-0.23,0.12,-0.59,-0.30,0.07,0.79,\\n -0.43,0.84,-0.43,0.71,-0.32,0.42,-0.22,-0.03,0.55,-0.06,-0.06,0.95,0.52,\\n 0.14,0.54,0.03,1.02,-0.17,-0.28,0.16,-0.01,0.02,-0.47,-0.19,0.44,-0.16,\\n 0.08,0.26,-0.26,-0.08,0.16,-0.40,-0.39,0.08,0.65,0.04,-0.22,-0.34,-0.75,\\n -0.19,-0.66,0.19,0.20,0.75,-0.07,-0.31,-0.11,-0.70,-1.37,-0.14,0.28,0.15,\\n 0.27,-0.99,0.37,-0.18,0.99,-0.06,-0.48,0.20,-0.33,0.33,0.41,-0.50,-0.19,\\n 0.08,0.02,0.19,0.14,-0.91,0.47,0.34,-0.41,-0.45,-0.45,-0.44,0.65,-0.25,\\n -1.28,-0.61,0.10,0.72,0.69,-0.19,-0.10,0.44,-0.51,0.11,-0.32,0.01,-0.00,\\n 0.09,0.34,-0.20,0.51,0.17,-0.20,-0.10,-0.05,0.13,0.39,0.79,-0.17,0.07,\\n -0.32,0.70,-0.21,0.13,-0.09,-1.03,-0.30,-0.75,0.56,1.09,0.22,0.43,-0.29,\\n 0.38,-0.01,0.15,0.97,0.30,-0.26,0.24,-0.12,0.09,0.07,0.02,-0.06,0.22,0.27,\\n -0.32,-0.15,-0.51,-0.46,0.19,-0.45,0.40,0.74,-0.46,-0.06,-0.31,-0.50,\\n -0.05,0.66,-0.07,-0.65,-0.06,0.22,0.14,-1.25,-0.19,-0.41,-0.44,0.25,0.97,\\n 0.09,0.02,1.09,-0.79,0.40,0.44,-0.08,0.26,0.15,0.19,0.39,0.23,-0.24,-0.57,\\n 0.94,-0.27,0.11,-0.53,-0.84,-0.27,-0.34,0.53,-0.18,0.23,0.46,0.11,0.22,\\n 1.31,0.18,-0.55,-0.80,0.25,0.11,0.01,-0.38,0.33,0.50,0.00,0.52,-0.86,\\n -0.25,0.21,-0.04,-0.00,0.65,-0.10,-0.21,-0.65,0.14,0.46,-0.88,0.55,-0.59,\\n -0.42,0.10,0.73,0.27,-0.03,-0.63,0.10,-0.07,0.79,0.99,-0.60,-0.22,0.22,\\n -0.16,0.05,-0.34,-0.12,0.48,0.43,0.29,0.32,-0.04,-0.31,-0.66,-0.41,-0.22,\\n 0.93,0.07,0.31,0.73,-0.68,-0.02,0.79,0.38,-0.33,0.24,0.67,-0.24,-1.18,\\n -0.22,-0.02,-0.60,0.08,-0.28,-1.15,-0.74,0.34,-0.61,-0.10,0.77,-0.25,\\n -0.89,-0.23,0.35,0.05,0.05,-0.37,-0.16,0.39,0.98,0.38,0.02,0.30,0.22,\\n -0.80,-0.75,-0.19,-0.17,0.06,0.20,-0.14,-0.23,-0.27,0.41,0.68,0.36,-0.80,\\n 0.68,-0.14,-0.17,0.05,0.38,0.50,0.15,-0.14,0.04,-0.20,-0.19,-0.40,-0.23,\\n -0.14,0.27,0.75,-0.18,-0.13,0.04,-0.38,0.44,0.07,-0.12,0.23,0.01,0.51,\\n -0.03,0.12,0.57,-0.08,0.53,0.27,0.91,0.45,-0.50,0.24,-0.16,0.82,-0.62,\\n -0.16,-0.12,-0.05,0.68,0.50,-0.24,-0.78,0.12,0.13,0.11,-1.10,-0.73,-0.36,\\n 0.38,0.44,0.04,-0.38,0.07,0.13,-0.74,0.33,-0.53,-0.10,0.22,0.40,-0.29,\\n -0.73,0.69,0.42,0.36,-0.28,0.51,0.39,0.92,0.19,-0.29,-0.31,-0.15,-0.08,\\n -0.06,-0.30,-0.19,-0.02,-0.20,-0.55,0.49,-0.83,-0.08,-0.52,0.47,-0.48]'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qv = np.array(model.words2vector('Active ingredient'))\n",
    "qv = np.array2string(qv, separator=',', formatter={'float_kind': lambda x: \"%.2f\" % x})\n",
    "qv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'http://localhost:8983/solr/ir_updated/select?indent=true&q.op=OR&&q={!knn f=feature_vector topK=10}' + qv\n",
    "r = requests.get(url = URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"response.txt\", \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
